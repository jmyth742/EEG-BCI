{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WorkingLSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmyth742/EEG-BCI/blob/master/WorkingLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQmrt_1f700y",
        "colab_type": "code",
        "outputId": "05d6c690-a422-432f-f2b9-e4a3d7126c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (1.12.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.4.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix9UKJAB71ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "##### START OF ADDITION OF MY CODE\n",
        "\n",
        "import numpy as np\n",
        "import os.path\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import sys\n",
        "\n",
        "## PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import Tensor\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "import math #for calculus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e8xUsGy71zD",
        "colab_type": "code",
        "outputId": "d95497ef-7165-4f62-b3d9-fcd43994f7f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "## END OF IMPORTS\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#file_id = '1FrXb6rTyqpE5SmNtP8HhygDmFf9Lw896'\n",
        "file_id = '1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG' ##1.mat\n",
        "#https://drive.google.com/open?id=1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx\n",
        "file_id = '1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx'\n",
        "#https://drive.google.com/open?id=1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('./train3.mat')\n",
        "#mat = loadmat('train3.mat')\n",
        "mat = sio.loadmat('train3.mat', squeeze_me=True, struct_as_record=False)\n",
        "data=[]\n",
        "\n",
        "o=mat['o']\n",
        "\n",
        "data=mat['o'].data\n",
        "data_set=mat['o'].data\n",
        "#print(data[200][21])\n",
        "labels=mat['o'].marker\n",
        "\n",
        "newlabels = np.zeros([data.shape[0],4])\n",
        "\n",
        "pos=np.zeros((22,667000), dtype=int)\n",
        "found = np.zeros([1,])\n",
        "#clean the shit out of it\n",
        "while np.amax(labels) > 3:\n",
        "    ind = np.argmax(labels)\n",
        "    found = np.append(found,np.array([ind]), axis=0)\n",
        "    labels[ind] = 0\n",
        "    data[ind,:] = np.zeros([22,])\n",
        "    \n",
        "print(data.shape)   \n",
        "#print(np.amax(labels))\n",
        "#print(found.shape)\n",
        "#print(found)\n",
        "\n",
        "inside = 0\n",
        "for y in labels:\n",
        "  if inside % 10000 == 0:\n",
        "    #print(inside)\n",
        "    newlabels[inside,y] = 1\n",
        "    inside += 1\n",
        "\n",
        "labeled_data = (data,labels)\n",
        "\n",
        "clean_data= np.hstack((data,labels.reshape((labels.shape[0],1))))\n",
        "data= np.hstack((data,labels.reshape((labels.shape[0],1))))\n",
        "\n",
        "clean_data = clean_data.astype('float32')\n",
        "data = data.astype('float32')\n",
        "print(data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(667000, 22)\n",
            "(667000, 23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qdg_beyhBp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_builder(seq_len, batch, data):\n",
        "  seq = torch.zeros(seq_len,batch,23)\n",
        "  j=0\n",
        "  idx=0\n",
        "  #seq = torch.zeros(time_seq,batch_size//time_seq,22)  \n",
        "  seq = np.zeros([seq_len,batch,23])\n",
        "  #for i in range(trim_start,finish_trim):\n",
        "  for i in range(len(data),1):\n",
        "    #if data[i][22] !=0:\n",
        "      #start = i -100\n",
        "    seq[idx][j][:] = data[i][:]\n",
        "    idx=idx+1\n",
        "    if idx == time_seq-1:\n",
        "      idx=0\n",
        "      j=j+1       \n",
        "\n",
        "  return seq\n",
        "  \n",
        "  \n",
        "  \n",
        "#def label_seq_builder():\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLQH80ZO72A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class eeg_LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(eeg_LSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(22, 4, 2)\n",
        "        #torch.nn.init.xavier_normal_(self.lstm.weight)\n",
        "        hidden = (torch.randn(2, 1, 4),\n",
        "                  torch.randn(1, 1, 4))\n",
        "    def forward(self, x):\n",
        "        #for i in inputs:\n",
        "        r_out, _ = self.lstm(i, hidden)\n",
        "        output, hidden = F.softmax(r_out) \n",
        "          \n",
        "        return output\n",
        "      \n",
        "      \n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, input_size=22, hidden_size=22, output_size=4,\n",
        "                 device='cuda:0'):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.i2h = nn.LSTM(input_size, 22,hidden_size,bias=False,batch_first=False)\n",
        "        #self.i2o = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, input, hidden=None, cell=None, device='cuda:0'):\n",
        "        outputs = []\n",
        "        if hidden==None:\n",
        "          #print(\"hidden input hidden:\",input.shape[1])\n",
        "          hidden = self.init_hidden(input.shape[1]) \n",
        "          hidden.to(device)\n",
        "        if cell==None:\n",
        "          #print(\"hidden input cell:\",input.shape[1])\n",
        "          cell = self.init_hidden(input.shape[1])\n",
        "          #cell.to(device)\n",
        "        #for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
        "        output, (_,_)= self.i2h(input, (hidden,cell))\n",
        "\n",
        "        #output = self.i2o(output)\n",
        "          #print('output',output.shape)\n",
        "        timesteps, batch, C = output.size()\n",
        "        out = output.view(timesteps*batch,C)\n",
        "          #outputs += [out]\n",
        "          #print('shape output', output.shape)\n",
        "        #output = F.softmax(output, dim=0)\n",
        "\n",
        "        outputs = output.view(1,timesteps*batch,C)\n",
        "        return outputs\n",
        "\n",
        "    def init_hidden(self,shape=1, device='cuda:0'):\n",
        "        return torch.zeros(22, shape, self.hidden_size).to(device)\n",
        "      \n",
        "    def init_cell(self,shape=1, device='cuda:0'):\n",
        "        return torch.zeros(22, shape, self.hidden_size).to(device)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0AOXdUY71-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_optimizer(net, lr):\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=0.00001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0.00001, amsgrad=False)\n",
        "  #optimizer = torch.optim.SGD(net.parameters(), lr=0.0000000001, weight_decay=0.9, momentum=0.9)\n",
        "  return optimizer\n",
        "\n",
        "def get_cost_function():\n",
        "  cost_function = torch.nn.CrossEntropyLoss()\n",
        "  return cost_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d81GEfbr717x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(batch_size,test_batch_size=256,step=1):\n",
        "  full_data = data\n",
        "   \n",
        "  #print(full_data.shape)\n",
        "  # Create train and validation splits\n",
        "  num_samples = len(full_data)\n",
        "  training_samples = int(num_samples)\n",
        "  #validation_samples = num_samples - training_samples  \n",
        "  \n",
        "\n",
        "  training=data[:training_samples]\n",
        "  #print(training.shape)\n",
        "  #validation=data[training_samples:]\n",
        "\n",
        "  # Initialize dataloaders\n",
        "  train_loader = torch.utils.data.DataLoader(training, batch_size, shuffle=False)\n",
        "  #val_loader = torch.utils.data.DataLoader(validation, test_batch_size, shuffle=False)\n",
        "  #test_loader = torch.utils.data.DataLoader(test_data, test_batch_size, shuffle=False)\n",
        "  \n",
        "  return train_loader#, val_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYpGtVU-715w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "def test(time_seq, batch_size, net, data_loader, cost_function, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "  print(\"test func\")\n",
        "  features = 22\n",
        "  i = 0\n",
        "  net.eval() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  #xtrain  = torch.zeros(time_seq,batch_size//time_seq,features\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs) in enumerate(data_loader):\n",
        "      \n",
        "      xtrain = inputs[:,:22]# = inputs[:,0:22]\n",
        "      labels = inputs[:,22:23]\n",
        "      \"\"\"if batch_idx % 50 == 0:\n",
        "        \n",
        "        print('xtrain 0 ', xtrain[0])\n",
        "        print('labels',labels[0])\"\"\"\n",
        "        \n",
        "        \n",
        "      train = Variable(torch.FloatTensor(xtrain.reshape(290,5,22))).to(device)#.reshape(batch size, seq len, channels)\n",
        "\n",
        "      output_seq = net(train)\n",
        "\n",
        "      \n",
        "      labels = labels.reshape(1450)\n",
        "\n",
        "      targets = Variable(torch.LongTensor(labels.long())).to(device)\n",
        "      loss = cost_function(output_seq[-1], targets)\n",
        "      \n",
        "      # Better print something\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = output_seq[-1].max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "\n",
        "def train(time_seq, batch_size,net,data_loader,optimizer,cost_function, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "  print(\"train function ----\")\n",
        "  features = 22\n",
        "  xtrain  = torch.zeros(time_seq,batch_size,features)\n",
        "  \n",
        "  net.train() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  #for i in range((step//batch_size)-1):\n",
        "\n",
        "  for batch_idx, (inputs) in enumerate(data_loader):\n",
        "    # Reset the optimizer\n",
        "      optimizer.zero_grad()\n",
        "    \n",
        "      xtrain = inputs[:,:22]# = inputs[:,0:22]\n",
        "      labels = inputs[:,22:23]\n",
        "      \"\"\"if batch_idx % 50 == 0:\n",
        "        \n",
        "        print('xtrain 0 ', xtrain[0])\n",
        "        print('labels',labels[0])\"\"\"\n",
        "      \n",
        "      train = Variable(torch.FloatTensor(xtrain.reshape(290,5,22))).to(device)#.reshape(batch size, seq len, channels)\n",
        "\n",
        "      output_seq = net(train)\n",
        "      \n",
        "      labels = labels.reshape(1450)\n",
        "\n",
        "      targets = Variable(torch.LongTensor(labels.long())).to(device)\n",
        "      loss = cost_function(output_seq[-1], targets)\n",
        "      \n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "    \n",
        "      # Update parameters\n",
        "      optimizer.step()\n",
        "      \n",
        "      # Better print something\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = output_seq[-1].max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Lb7Z90711X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Input arguments\n",
        "  batch_size: Size of a mini-batch\n",
        "  device: GPU where you want to train your network\n",
        "  weight_decay: Weight decay co-efficient for regularization of weights\n",
        "  momentum: Momentum for SGD optimizer\n",
        "  epochs: Number of epochs for training the network\n",
        "'''\n",
        "\n",
        "def main(batch_size=1450, \n",
        "         device='cuda:0', \n",
        "         learning_rate=0.001, \n",
        "         time_seq=29,\n",
        "         wd=0.9,\n",
        "         epochs=200):\n",
        "  \n",
        "  #train_loader, val_loader = get_data(batch_size,batch_size)\n",
        "  train_loader = get_data(batch_size,batch_size)\n",
        "  net = SimpleLSTM().to(device)\n",
        "  #net = SimpleLSTM()#.to(device)\n",
        "  e=0\n",
        "  optimizer = get_optimizer(net, learning_rate)\n",
        "  \n",
        "  cost_function = get_cost_function()\n",
        "\n",
        "  print('Before training:')\n",
        "  train_loss, train_accuracy = test(time_seq, batch_size, net, train_loader, cost_function)\n",
        "  #val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  #test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.10f}, Training accuracy {:.10f}'.format(train_loss, train_accuracy))\n",
        "  #print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  #print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "  for e in range(epochs):\n",
        "    train_loss, train_accuracy = train(time_seq, batch_size,net, train_loader, optimizer, cost_function)\n",
        "    #val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "    print('Epoch: {:d}',e)\n",
        "    print('\\t Training loss {:.10f}, Training accuracy {:.10f}'.format(train_loss, train_accuracy))\n",
        "    #print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "\n",
        "  print('After training:')\n",
        "  #train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "  #val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  #test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  #print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  #print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jytoAabAPmE",
        "colab_type": "code",
        "outputId": "a5afbe8c-e443-41a9-f3ab-fb7ca1dfaa9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before training:\n",
            "test func\n",
            "\t Training loss 0.0021317533, Training accuracy 10.3442278861\n",
            "-----------------------------------------------------\n",
            "train function ----\n",
            "Epoch: {:d} 0\n",
            "\t Training loss 0.0021317533, Training accuracy 10.5124437781\n",
            "-----------------------------------------------------\n",
            "train function ----\n",
            "Epoch: {:d} 1\n",
            "\t Training loss 0.0021317533, Training accuracy 10.7890554723\n",
            "-----------------------------------------------------\n",
            "train function ----\n",
            "Epoch: {:d} 2\n",
            "\t Training loss 0.0021317533, Training accuracy 11.0106446777\n",
            "-----------------------------------------------------\n",
            "train function ----\n",
            "Epoch: {:d} 3\n",
            "\t Training loss 0.0021317533, Training accuracy 11.1929535232\n",
            "-----------------------------------------------------\n",
            "train function ----\n",
            "Epoch: {:d} 4\n",
            "\t Training loss 0.0021317533, Training accuracy 11.3812593703\n",
            "-----------------------------------------------------\n",
            "train function ----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grVJfd8TAPjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6jdnDDLAPhG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "f409ec9e-a0e6-45d5-b760-3d454a435827"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Sequence(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Sequence, self).__init__()\n",
        "        self.lstm1 = nn.LSTMCell(1, 51)\n",
        "        self.lstm2 = nn.LSTMCell(51, 51)\n",
        "        self.linear = nn.Linear(51, 1)\n",
        "\n",
        "    def forward(self, input, future = 0):\n",
        "        outputs = []\n",
        "        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
        "        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
        "        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
        "        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
        "\n",
        "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
        "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
        "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
        "            output = self.linear(h_t2)\n",
        "            outputs += [output]\n",
        "        for i in range(future):# if we should predict the future\n",
        "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
        "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
        "            output = self.linear(h_t2)\n",
        "            outputs += [output]\n",
        "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # set random seed to 0\n",
        "    np.random.seed(0)\n",
        "    torch.manual_seed(0)\n",
        "    # load data and make training set\n",
        "    data1 = data.astype('double')\n",
        "    data1 = data1[:100,:22]\n",
        "    input = torch.from_numpy(data[3:, :-1])\n",
        "    target = torch.from_numpy(data[3:, 1:])\n",
        "    test_input = torch.from_numpy(data[:3, :-1])\n",
        "    test_target = torch.from_numpy(data[:3, 1:])\n",
        "    # build the model\n",
        "    seq = Sequence()\n",
        "    seq.double()\n",
        "    criterion = nn.MSELoss()\n",
        "    # use LBFGS as optimizer since we can load the whole data to train\n",
        "    optimizer = optim.LBFGS(seq.parameters(), lr=0.8)\n",
        "    #begin to train\n",
        "    for i in range(15):\n",
        "        print('STEP: ', i)\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            out = seq(input)\n",
        "            print('target shape ', target.shape)\n",
        "            print('out shape ', out.shape)\n",
        "            loss = criterion(out, target)\n",
        "            print('loss:', loss.item())\n",
        "            loss.backward()\n",
        "            return loss\n",
        "        optimizer.step(closure)\n",
        "        # begin to predict, no need to track gradient here\n",
        "        with torch.no_grad():\n",
        "            future = 1000\n",
        "            print(test_input.shape)\n",
        "            pred = seq(test_input, future=future)\n",
        "            loss = criterion(pred[:, :-future], test_target)\n",
        "            print('test loss:', loss.item())\n",
        "            y = pred.detach().numpy()\n",
        "        # draw the result\n",
        "        plt.figure(figsize=(30,10))\n",
        "        plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
        "        plt.xlabel('x', fontsize=20)\n",
        "        plt.ylabel('y', fontsize=20)\n",
        "        plt.xticks(fontsize=20)\n",
        "        plt.yticks(fontsize=20)\n",
        "        def draw(yi, color):\n",
        "            plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n",
        "            plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n",
        "        draw(y[0], 'r')\n",
        "        draw(y[1], 'g')\n",
        "        draw(y[2], 'b')\n",
        "        plt.savefig('predict%d.pdf'%i)\n",
        "        plt.close()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STEP:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-9b65660529c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;31m# begin to predict, no need to track gradient here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# evaluate initial f(x) and df/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0morig_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mcurrent_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-9b65660529c1>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target shape '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out shape '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-9b65660529c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, future)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mh_t2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_t2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m         )\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Float for argument #4 'mat1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoAMamJHAPe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaTV3G7JWlth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "def test(time_seq, batch_size, net, data_loader, cost_function, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "  print(\"test func\")\n",
        "  features = 22\n",
        "  net.eval() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  #xtrain  = torch.zeros(time_seq,batch_size//time_seq,features\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs) in enumerate(data_loader):\n",
        "\n",
        "      ## lets turn the data into batches for the LSTM\n",
        "      formatted = sequence_builder(145,23,inputs)\n",
        "      xtrain = formatted[:,:,:22]# = inputs[:,0:22]\n",
        "      labels = formatted[:,:,22:23]\n",
        "      lab = torch.zeros(23,1)\n",
        "      for j in range(23):\n",
        "        #print(labels[:][j][0].max())\n",
        "        lab[j][0] = labels[:][j][0].max()\n",
        "      train = Variable(torch.FloatTensor(xtrain)).to(device)#.reshape(batch size, seq len, channels)\n",
        "\n",
        "      \n",
        "      output_seq = net(train)\n",
        "      \n",
        "      targets = Variable(torch.LongTensor(lab.reshape([23]).long())).to(device)\n",
        "      \n",
        "      loss = cost_function(output_seq[-1], targets)\n",
        "      \n",
        "      # Better print something\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = output_seq[-1].max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "\n",
        "def train(time_seq, batch_size,net,data_loader,optimizer,cost_function, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "  print(\"train func\")\n",
        "  features = 22\n",
        "  xtrain  = torch.zeros(time_seq,batch_size,features)\n",
        "  \n",
        "  net.train() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  #for i in range((step//batch_size)-1):\n",
        "  for batch_idx, (inputs) in enumerate(data_loader):\n",
        "     # Load data into GPU\n",
        "      ## lets turn the data into batches for the LSTM\n",
        "      formatted = sequence_builder(145,23,inputs)\n",
        "      xtrain = formatted[:,:,:22]# = inputs[:,0:22]\n",
        "      labels = formatted[:,:,22:23]\n",
        "      lab = torch.zeros(23,1)\n",
        "      for j in range(23):\n",
        "        #print(labels[:][j][0].max())\n",
        "        lab[j][0] = labels[:][j][0].max()\n",
        "      train = Variable(torch.FloatTensor(xtrain)).to(device)#.reshape(batch size, seq len, channels)\n",
        "\n",
        "      output_seq = net(train)\n",
        "      \n",
        "      targets = Variable(torch.LongTensor(lab.reshape([23]).long())).to(device)\n",
        "\n",
        "      \n",
        "      loss = cost_function(output_seq[-1], targets)\n",
        "      \n",
        "      # Better print something\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = output_seq[-1].max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ-OLMtvZwbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "e74510f7-3234-4b38-ae5d-180591a35149"
      },
      "source": [
        "inputs = [autograd.Variable(torch.randn((1, 3)))\n",
        "          for _ in range(5)]  # make a sequence of length 5\n",
        "\n",
        "# initialize the hidden state.\n",
        "hidden = (autograd.Variable(torch.randn(1, 1, 3)),\n",
        "          autograd.Variable(torch.randn((1, 1, 3))))\n",
        "for i in inputs:\n",
        "    # Step through the sequence one element at a time.\n",
        "    # after each step, hidden contains the hidden state.\n",
        "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
        "\n",
        "# alternatively, we can do the entire sequence all at once.\n",
        "# the first value returned by LSTM is all of the hidden states throughout\n",
        "# the sequence. the second is just the most recent hidden state\n",
        "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
        "# The reason for this is that:\n",
        "# \"out\" will give you access to all hidden states in the sequence\n",
        "# \"hidden\" will allow you to continue the sequence and backpropogate,\n",
        "# by passing it as an argument  to the lstm at a later time\n",
        "# Add the extra 2nd dimension\n",
        "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
        "hidden = (autograd.Variable(torch.randn(1, 1, 3)), autograd.Variable(\n",
        "    torch.randn((1, 1, 3))))  # clean out hidden state\n",
        "out, hidden = lstm(inputs, hidden)\n",
        "print(out)\n",
        "print(hidden)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-ee0d3dc7e998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs = [autograd.Variable(torch.randn((1, 3)))\n\u001b[0;32m----> 2\u001b[0;31m           for _ in range(5)]  # make a sequence of length 5\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# initialize the hidden state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m hidden = (autograd.Variable(torch.randn(1, 1, 3)),\n",
            "\u001b[0;32m<ipython-input-81-ee0d3dc7e998>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs = [autograd.Variable(torch.randn((1, 3)))\n\u001b[0;32m----> 2\u001b[0;31m           for _ in range(5)]  # make a sequence of length 5\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# initialize the hidden state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m hidden = (autograd.Variable(torch.randn(1, 1, 3)),\n",
            "\u001b[0;31mNameError\u001b[0m: name 'autograd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsekCH22713g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_seq=400\n",
        "batch_size = 1586\n",
        "trim_start = 35700\n",
        "finish_trim = 634400\n",
        "i= 35700\n",
        "idx=0\n",
        "j=0\n",
        "#seq = torch.zeros(time_seq,batch_size//time_seq,22)  \n",
        "seq = np.zeros([time_seq,batch_size,23])\n",
        "for i in range(trim_start,finish_trim):\n",
        "  if clean_data[i][22] !=0:\n",
        "    start = i -100\n",
        "    seq[idx][j][:] = clean_data[start][:]\n",
        "    idx=idx+1\n",
        "    if idx == 399:\n",
        "      idx=0\n",
        "      j=j+1\n",
        "print(seq.shape)    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}