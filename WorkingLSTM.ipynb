{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WorkingLSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmyth742/EEG-BCI/blob/master/WorkingLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQmrt_1f700y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "d2914a0c-ee3e-4f16-c1ba-0badd70f6c4a"
      },
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.12.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix9UKJAB71ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "##### START OF ADDITION OF MY CODE\n",
        "\n",
        "import numpy as np\n",
        "import os.path\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import sys\n",
        "\n",
        "## PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import Tensor\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "import math #for calculus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e8xUsGy71zD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## END OF IMPORTS\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#file_id = '1FrXb6rTyqpE5SmNtP8HhygDmFf9Lw896'\n",
        "file_id = '1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG' ##1.mat\n",
        "#https://drive.google.com/open?id=1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx\n",
        "file_id = '1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx'\n",
        "#https://drive.google.com/open?id=1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('./train3.mat')\n",
        "#mat = loadmat('train3.mat')\n",
        "mat = sio.loadmat('train3.mat', squeeze_me=True, struct_as_record=False)\n",
        "data=[]\n",
        "\n",
        "o=mat['o']\n",
        "\n",
        "data=mat['o'].data\n",
        "data_set=mat['o'].data\n",
        "#print(data[200][21])\n",
        "labels=mat['o'].marker\n",
        "\n",
        "newlabels = np.zeros([data.shape[0],4])\n",
        "\n",
        "pos=np.zeros((22,667000), dtype=int)\n",
        "found = np.zeros([1,])\n",
        "#clean the shit out of it\n",
        "while np.amax(labels) > 3:\n",
        "    ind = np.argmax(labels)\n",
        "    found = np.append(found,np.array([ind]), axis=0)\n",
        "    labels[ind] = 0\n",
        "    data[ind,:] = np.zeros([22,])\n",
        "    \n",
        "   \n",
        "#print(np.amax(labels))\n",
        "#print(found.shape)\n",
        "#print(found)\n",
        "\n",
        "inside = 0\n",
        "for y in labels:\n",
        "  if inside % 10000 == 0:\n",
        "    #print(inside)\n",
        "    newlabels[inside,y] = 1\n",
        "    inside += 1\n",
        "\n",
        "labeled_data = (data,labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsekCH22713g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.hstack((data,labels.reshape((labels.shape[0],1))))\n",
        "data = data.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLQH80ZO72A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class eeg_LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(eeg_LSTM, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.lstm = nn.LSTM(22, 4, 2)\n",
        "        #torch.nn.init.xavier_normal_(self.lstm.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if hidden==None:\n",
        "          hidden = self.init_hidden(input.shape[1])\n",
        "          \n",
        "        if cell==None:\n",
        "          cell = self.init_hidden(input.shape[1])\n",
        "          \n",
        "        output, (_,_)= self.i2h(input, (hidden,cell))\n",
        "        r_out, _ = self.lstm(input, (hidden,cell))\n",
        "        output = F.softmax(r_out) \n",
        "        return output\n",
        "      \n",
        "      \n",
        "    def init_hidden(self,shape=1):\n",
        "        return torch.zeros(1, shape, self.hidden_size)\n",
        "      \n",
        "    def init_cell(self,shape=1):\n",
        "        return torch.zeros(1, shape, self.hidden_size)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0AOXdUY71-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_optimizer(net, lr):\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "  #oprimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "  return optimizer\n",
        "\n",
        "def get_cost_function():\n",
        "  cost_function = torch.nn.CrossEntropyLoss()\n",
        "  return cost_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d81GEfbr717x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(batch_size,test_batch_size=256,step=1):\n",
        "  full_data = data\n",
        "  #print(full_data.shape)\n",
        "  # Create train and validation splits\n",
        "  num_samples = len(full_data)\n",
        "  training_samples = int(num_samples)\n",
        "  #validation_samples = num_samples - training_samples  \n",
        "  \n",
        "\n",
        "  training=data[:training_samples]\n",
        "  #validation=data[training_samples:]\n",
        "\n",
        "  # Initialize dataloaders\n",
        "  train_loader = torch.utils.data.DataLoader(training, batch_size, shuffle=False)\n",
        "  #val_loader = torch.utils.data.DataLoader(validation, test_batch_size, shuffle=False)\n",
        "  #test_loader = torch.utils.data.DataLoader(test_data, test_batch_size, shuffle=False)\n",
        "  \n",
        "  return train_loader#, val_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYpGtVU-715w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(time_seq, batch_size, net, data_loader, cost_function, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "  net.eval() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs) in enumerate(data_loader):\n",
        "      # Load data into GPU\n",
        "      xtrain = inputs[:,0:22]\n",
        "      labels = inputs[:,22]\n",
        "      train = Variable(torch.FloatTensor(xtrain.reshape(time_seq,batch_size,22))).to(device)#.reshape(batch size, seq len, channels)\n",
        "      labels = inputs[:,22]\n",
        "      \n",
        "      #print(\"shape of labels\", labels.shape)\n",
        "      #print(\"Contents of labels\", labels)\n",
        "      \n",
        "      output_seq = net(train)\n",
        "      last_output = output_seq[-1]\n",
        "      \n",
        "      targets = Variable(labels.long()).to(device)\n",
        "      loss = cost_function(last_output, targets)\n",
        "      \n",
        "      # Better print something\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = last_output.max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "\n",
        "def train(time_seq, batch_size,net,data_loader,optimizer,cost_function, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "  \n",
        "  net.train() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  #for i in range((step//batch_size)-1):\n",
        "  for batch_idx, (inputs) in enumerate(data_loader):\n",
        "     # Load data into GPU\n",
        "      xtrain = inputs[:,0:22]\n",
        "      labels = inputs[:,22]\n",
        "      train = Variable(torch.FloatTensor(xtrain.reshape(time_seq,batch_size,22))).to(device)#.reshape(batch size, seq len, channels)\n",
        "      \n",
        "      #input_seq = Variable(torch.randn(time_steps, batch_size, in_size))\n",
        "      output_seq = net(train)\n",
        "      last_output = output_seq[-1]\n",
        "      \n",
        "      #targets = Variable(torch.LongTensor(batch_size).random_(0, 3)).to(device)\n",
        "      targets = Variable(labels.long()).to(device)\n",
        "      loss = cost_function(last_output, targets)\n",
        "      \n",
        "      # Better print something\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = last_output.max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Lb7Z90711X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Input arguments\n",
        "  batch_size: Size of a mini-batch\n",
        "  device: GPU where you want to train your network\n",
        "  weight_decay: Weight decay co-efficient for regularization of weights\n",
        "  momentum: Momentum for SGD optimizer\n",
        "  epochs: Number of epochs for training the network\n",
        "'''\n",
        "\n",
        "def main(batch_size=3335, \n",
        "         device='cuda:0', \n",
        "         learning_rate=0.0000000001, \n",
        "         time_seq=1,\n",
        "         epochs=500):\n",
        "  \n",
        "  #train_loader, val_loader = get_data(batch_size,batch_size)\n",
        "  train_loader = get_data(batch_size,batch_size)\n",
        "  net = eeg_LSTM().to(device)\n",
        "  \n",
        "  optimizer = get_optimizer(net, learning_rate)\n",
        "  \n",
        "  cost_function = get_cost_function()\n",
        "\n",
        "  print('Before training:')\n",
        "  train_loss, train_accuracy = test(time_seq, batch_size, net, train_loader, cost_function)\n",
        "  #val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  #test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  #print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  #print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "  for e in range(epochs):\n",
        "    #train_loss, train_accuracy = train(time_se1, batch_size,net, train_loader, optimizer, cost_function)\n",
        "    #val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "    print('Epoch: {:d}'.format(e+1))\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    #print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "\n",
        "  print('After training:')\n",
        "  #train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "  #val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  #test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  #print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  #print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jytoAabAPmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grVJfd8TAPjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6jdnDDLAPhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoAMamJHAPe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}