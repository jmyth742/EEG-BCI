{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-CNN-LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmyth742/EEG-BCI/blob/master/DL_CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "walmaCfwHT07",
        "colab_type": "code",
        "outputId": "05dac022-6e00-4950-b108-190c2068c8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (1.12.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU-bZAV-HUrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "##### START OF ADDITION OF MY CODE\n",
        "\n",
        "import numpy as np\n",
        "import os.path\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import sys\n",
        "\n",
        "## PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import Tensor\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "import math #for calculus\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlJq32ymHUtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## END OF IMPORTS\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#file_id = '1FrXb6rTyqpE5SmNtP8HhygDmFf9Lw896'\n",
        "file_id = '1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG' ##1.mat\n",
        "#https://drive.google.com/open?id=1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx\n",
        "file_id = '1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx'\n",
        "#https://drive.google.com/open?id=1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('./train3.mat')\n",
        "#mat = loadmat('train3.mat')\n",
        "mat = sio.loadmat('train3.mat', squeeze_me=True, struct_as_record=False)\n",
        "data=[]\n",
        "\n",
        "## in class      \n",
        "device='cuda:0'\n",
        "learning_rate=0.01\n",
        "weight_decay=0.000001 \n",
        "momentum=0.9\n",
        "batch_size=200\n",
        "\n",
        "o=mat['o']\n",
        "\n",
        "data=mat['o'].data\n",
        "#print(data[200][21])\n",
        "labels=mat['o'].marker\n",
        "\n",
        "newlabels = np.zeros([data.shape[0],4])\n",
        "\n",
        "#print(newlabels.shape)\n",
        "#print(labels.shape)\n",
        "\n",
        "#print(np.amax(labels))\n",
        "\n",
        "found = np.zeros([1,])\n",
        "#print(found.shape)\n",
        "\n",
        "#clean the shit out of it\n",
        "while np.amax(labels) > 3:\n",
        "    ind = np.argmax(labels)\n",
        "    found = np.append(found,np.array([ind]), axis=0)\n",
        "    labels[ind] = 0\n",
        "    data[ind,:] = np.zeros([22,])\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "#print(np.amax(labels))\n",
        "#print(found.shape)\n",
        "#print(found)\n",
        "\n",
        "inside = 0\n",
        "for y in labels:\n",
        "  if inside % 10000 == 0:\n",
        "    #print(inside)\n",
        "    newlabels[inside,y] = 1\n",
        "    inside += 1\n",
        "  \n",
        "#print(newlabels.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhXrIcR8HUvp",
        "colab_type": "code",
        "outputId": "8e954f4c-d76c-48b6-fccb-694d69a959de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "## video maker and data extractor\n",
        "\n",
        "pos=np.zeros((22,3), dtype=int)\n",
        "\n",
        "pos[0]=-2,10,0\n",
        "pos[1]=2,10,0\n",
        "pos[3]=-4,7,3\n",
        "pos[4]=4,7,3\n",
        "pos[5]=-5,0,4\n",
        "pos[6]=5,0,4\n",
        "pos[7]=-4,-7,3\n",
        "pos[8]=4,-7,3\n",
        "pos[9]=-2,-10,0\n",
        "pos[10]=2,-10,0\n",
        "pos[11]=-7,0,-5\n",
        "pos[12]=7,0,5\n",
        "pos[13]=-6,6,0\n",
        "pos[14]=6,6,0\n",
        "pos[15]=-7,0,0\n",
        "pos[16]=7,0,0\n",
        "pos[17]=-6,-6,0\n",
        "pos[18]=6,-6,0\n",
        "pos[19]=0,7,4\n",
        "pos[20]=0,0,6\n",
        "pos[21]=0,-7,4\n",
        "\n",
        "def make_3d_point(x,y,z,r,theta,phi):\n",
        "  return [\n",
        "      x + int(r * math.cos(theta)*math.sin(phi)),\n",
        "      y + int(r * math.sin(theta)*math.sin(phi)),\n",
        "      z + int(r * math.cos(phi))\n",
        "         ]\n",
        "\n",
        "def make_3d_image(image3d_data,shift):\n",
        "  \n",
        " # print(\"started a 3d image\")\n",
        "  \n",
        "  #creating the matrix\n",
        "  matrix = np.zeros([12,16,22]) # z,x,y\n",
        "  \n",
        "  #looping through data\n",
        "  for point in image3d_data:\n",
        "    \n",
        "    # creating the indice by shifting the coordinate system from the center to left corner\n",
        "    newpoint = [int(point[0]) + 7,int(point[1]) + 10,int(point[2]) + 5]\n",
        "    \n",
        "    if newpoint[0] >= matrix.shape[1] or newpoint[1] >= matrix.shape[2] or newpoint[2] >= matrix.shape[0] or newpoint[0] < 0 or newpoint[1] < 0 or newpoint[2] < 0:\n",
        "      print(\"did not add point\")\n",
        "      print(newpoint)\n",
        "      print(matrix.shape)\n",
        "      continue\n",
        "\n",
        "      \n",
        "    #the maximum value\n",
        "    cap = 400 + shift #based on the data (a peak - maximum value is equal or higher than 400)\n",
        "    \n",
        "    #for scaling the values between 0 and 255\n",
        "    scale = 255/cap\n",
        "    \n",
        "    #assigning the value\n",
        "    if int(point[3]) >= 0 and int(point[3]) <= cap:\n",
        "      if matrix[newpoint[2],newpoint[0],newpoint[1]] == 0 or matrix[newpoint[2],newpoint[0],newpoint[1]] < int(point[3]*scale):\n",
        "        matrix[newpoint[2],newpoint[0],newpoint[1]] = int(point[3]*scale)\n",
        "\n",
        "    elif int(point[3]) > cap:\n",
        "      if matrix[newpoint[2],newpoint[0],newpoint[1]] == 0 or matrix[newpoint[2],newpoint[0],newpoint[1]] < int(cap*scale):\n",
        "        matrix[newpoint[2],newpoint[0],newpoint[1]] = int(cap*scale)\n",
        "    else:\n",
        "      if matrix[newpoint[2],newpoint[0],newpoint[1]] < 0:\n",
        "        matrix[newpoint[2],newpoint[0],newpoint[1]] = 0\n",
        "    \n",
        "    #creating variables for creating a virtual sphere around poi\n",
        "    rho = [2,3] # distance (in pixels) that we are interpolating from poi\n",
        "    #theta  angle in radians    [0,2pi]\n",
        "    #phi    angle in radians    [0, pi]\n",
        "    \n",
        "    #creating new interpolated points\n",
        "    for r in rho:\n",
        "      for theta in range(0,360,45):\n",
        "        for phi in range(0,180,45):\n",
        "          p = make_3d_point(newpoint[0],newpoint[1],newpoint[2],r,math.radians(theta),math.radians(phi))\n",
        "          \n",
        "          #checking if its in bounds\n",
        "          if p[0] < matrix.shape[1] and p[1] < matrix.shape[2] and p[2] < matrix.shape[0] and p[0] >= 0 and p[1] >= 0 and p[2] >= 0:\n",
        "\n",
        "            \n",
        "            #assigning the value to the matrix, scaled down by distance\n",
        "            if int(point[3]) >= 0 and int(point[3]) <= cap:\n",
        "              if matrix[p[2],p[0],p[1]] == 0:\n",
        "                matrix[p[2],p[0],p[1]] = int(point[3]/r*scale)\n",
        "            elif int(point[3]) > cap:\n",
        "              if matrix[p[2],p[0],p[1]] == 0:\n",
        "                matrix[p[2],p[0],p[1]] = int(cap/r*scale)\n",
        "            else:\n",
        "              if matrix[p[2],p[0],p[1]] == 0:\n",
        "                matrix[p[2],p[0],p[1]] = 0\n",
        "            \n",
        "  return matrix\n",
        "\n",
        "\n",
        "start = 81220\n",
        "end   = 86220\n",
        "#start = 0\n",
        "#end = 667000\n",
        "step = 1\n",
        "\n",
        "#shift the data because it has negative values\n",
        "shift_data = 300\n",
        "\n",
        "newdata = np.add(data,shift_data).reshape([22,data.shape[0]])\n",
        "\n",
        "video_stream = np.zeros([end-start,1,12,16,22])\n",
        "video_stream[0,0] = make_3d_image(np.hstack((pos,newdata[:,start].reshape([22,1]))),shift_data)\n",
        "\n",
        "print(np.hstack((pos,newdata[:,start].reshape([22,1]))))\n",
        "\n",
        "\n",
        "for t in range(start+step,end,step):\n",
        " \n",
        "  #create x,y,z,value for timestep t\n",
        "  data3d = np.hstack((pos,newdata[:,t].reshape([22,1])))\n",
        "  \n",
        "  #make image - with interpolated data for timestep t\n",
        "  result = make_3d_image(data3d,shift_data)\n",
        "  \n",
        "  #add image to video stream\n",
        "  video_stream[t-start,0] = result\n",
        "  \n",
        "  \n",
        "maxValue = np.amax(video_stream)\n",
        "minValue = np.amin(video_stream)\n",
        "\n",
        "#print(maxValue)\n",
        "#print(minValue)\n",
        "#print(video_stream[0,0,3])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ -2.    10.     0.   300.26]\n",
            " [  2.    10.     0.   385.54]\n",
            " [  0.     0.     0.   295.69]\n",
            " [ -4.     7.     3.   298.45]\n",
            " [  4.     7.     3.   317.37]\n",
            " [ -5.     0.     4.   281.27]\n",
            " [  5.     0.     4.   301.09]\n",
            " [ -4.    -7.     3.   297.56]\n",
            " [  4.    -7.     3.   300.  ]\n",
            " [ -2.   -10.     0.   299.14]\n",
            " [  2.   -10.     0.   295.  ]\n",
            " [ -7.     0.    -5.   307.31]\n",
            " [  7.     0.     5.   321.3 ]\n",
            " [ -6.     6.     0.   298.49]\n",
            " [  6.     6.     0.   287.8 ]\n",
            " [ -7.     0.     0.   300.  ]\n",
            " [  7.     0.     0.   306.79]\n",
            " [ -6.    -6.     0.   294.29]\n",
            " [  6.    -6.     0.   301.33]\n",
            " [  0.     7.     4.   305.38]\n",
            " [  0.     0.     6.   296.88]\n",
            " [  0.    -7.     4.   287.31]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j9nZCOzKGZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXFEMyYAHUyP",
        "colab_type": "code",
        "outputId": "fbe023ef-d003-43c8-9654-85be5de4c7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7245
        }
      },
      "source": [
        "\n",
        "\n",
        "class EEGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EEGNet, self).__init__()\n",
        "        self.T = 120\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(1,5,2, stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.conv2 = nn.Conv3d(5,10,(2,3,2), stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.conv3 = nn.Conv3d(10,5,3, stride=1,dilation=1)\n",
        "        self.conv4 = nn.Conv3d(5,5,(3,3,2), stride=1, dilation =1)\n",
        "        self.conv5 = nn.Conv3d(5,5,(1,2,1), stride=1, dilation =1)\n",
        "        self.pooling1 = nn.MaxPool3d((2,2,2), stride=1, dilation=1)\n",
        "        \n",
        "        #layer after max pool\n",
        "        self.conv6 = nn.Conv3d(5,5,3, stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.conv7 = nn.Conv3d(5,5,(3,3,2), stride=1,dilation=1)\n",
        "        self.conv8 = nn.Conv3d(5,5,(1,2,1), stride=1,dilation=1)\n",
        "        self.pooling2 = nn.MaxPool3d((3,3,2), stride=1, dilation=1)\n",
        "        \n",
        "        #Layer after next max pool \n",
        "        self.conv9 = nn.Conv3d(5,5,3, stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.conv10 = nn.Conv3d(5,5,(3,3,2), stride=1,dilation=1)\n",
        "        self.conv11 = nn.Conv3d(5,1,(1,2,1), stride=1,dilation=1)\n",
        "        self.pooling3 = nn.MaxPool3d((3,3,2), stride=1, dilation=1)\n",
        "        \n",
        "        #self.fc1 = nn.Linear(16 * 1 * 1, 10)\n",
        "        ## here is the start of the LSTM \n",
        "        self.rnn = nn.LSTM(16, 4, 2)\n",
        "        #self.fc1 = nn.Linear(4,4)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "      \n",
        "        # first set of CNNs and then a max pool\n",
        "        x = F.leaky_relu(self.conv1(x))\n",
        "        x = F.leaky_relu(self.conv2(x))       \n",
        "        x = F.leaky_relu(self.conv3(x))     \n",
        "        x = F.leaky_relu(self.conv4(x))\n",
        "        x = F.leaky_relu(self.conv5(x))\n",
        "        x = self.pooling1(x)\n",
        "        \n",
        "        # second set\n",
        "        \n",
        "        x = F.leaky_relu(self.conv6(x))\n",
        "        x = F.leaky_relu(self.conv7(x))\n",
        "        x = F.leaky_relu(self.conv8(x))\n",
        "        x = self.pooling2(x)\n",
        "        \n",
        "        # set 3  \n",
        "        \n",
        "        x = F.leaky_relu(self.conv9(x))\n",
        "        x = F.leaky_relu(self.conv10(x))\n",
        "        x = F.leaky_relu(self.conv11(x))\n",
        "        x = self.pooling3(x)\n",
        "        \n",
        " \n",
        "\n",
        "        #Start of LSTM\n",
        "        batch_size, timesteps, C, H, W = x.size()\n",
        "        c_in = x.view(batch_size * timesteps, C, H, W)\n",
        "        c_in = c_in[:,0,:,:]\n",
        "        #print(\"stsrting\")\n",
        "        #print(c_in.shape)\n",
        "        \n",
        "        r_out, _ = self.rnn(c_in)\n",
        "        #print(r_out.shape)\n",
        "        #print(\"endsing\")\n",
        "        \n",
        "        #t =  self.fc1(r_out)\n",
        "        #t = F.log_softmax(r_out, dim=0)\n",
        "        output = F.softmax(r_out)#, dim=0)\n",
        "        return output\n",
        "      \n",
        "## END OF ADDITION OF MY CODE\n",
        "      \n",
        "device='cuda:0'            \n",
        "net = EEGNet().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "#X_train = video_stream.astype('float32') # our generated image\n",
        "#y_train = torch.from_numpy(labels.reshape(667000,1)[start:end])#()2668000,1\n",
        "\n",
        "y_train = torch.from_numpy(labels.reshape(667000,1))#()2668000,1\n",
        "\n",
        "\n",
        "#batch_size = 115\n",
        "batch_size = 100\n",
        "#begin=3335\n",
        "#finish=6670\n",
        "begin = 0\n",
        "finish = 3000\n",
        "step=0\n",
        "t=0\n",
        "print(begin, finish, step)\n",
        "#print(y_train.max())\n",
        "#for epoch in range(0,X_train.shape[0],batch_size):  # loop over the dataset multiple times ##\n",
        "for epoch in range(0,200):\n",
        "  print(\"\\nEpoch \", epoch)\n",
        "  #print(\"t is before loop \", t)\n",
        "\n",
        "  for t in range(begin,finish,1):\n",
        "    #create x,y,z,value for timestep t\n",
        "    data3d = np.hstack((pos,newdata[:,t].reshape([22,1])))\n",
        "    #make image - with interpolated data for timestep t\n",
        "    result = make_3d_image(data3d,shift_data)\n",
        "    #add image to video stream\n",
        "    video_stream[t-begin,0] = result\n",
        "    \n",
        "  X_train = video_stream.astype('float32')# our generated image\n",
        "  y_train = torch.from_numpy(labels[begin:finish].reshape(finish-begin,1))#()2668000,1\n",
        "  #print(\"ytrain shape is \", y_train.shape)\n",
        "  begin = finish\n",
        "  #step = 3335\n",
        "  step = 3000\n",
        "  t = t+step\n",
        "  #print(\"t after loop is \", t)\n",
        "  finish = finish+step\n",
        "  #print(\"begin%s finish%s step%s \",begin, finish, step)        \n",
        "  running_loss = 0.0\n",
        "  #print(\"len xtrain \", len(X_train))\n",
        "  #print(\"division of train and batch \", len(X_train)//batch_size)\n",
        "  \n",
        "  for i in range((len(X_train)//batch_size)-1):        \n",
        "        s = i*batch_size\n",
        "        e = i*batch_size+batch_size\n",
        "        train = Variable(torch.tensor(X_train[s:e])).to(device)\n",
        "        #print(\"S is \", s)\n",
        "        #print(\"E is \", e)\n",
        "        out = net(train)\n",
        "        last_output = out[-1]\n",
        "        #print(\"y_train shape is \",y_train.shape)\n",
        "        #print(y_train[0:e-s].max())\n",
        "        target = Variable(torch.LongTensor([y_train[0:e-s].max()])).to(device)\n",
        "\n",
        "        #print(target)\n",
        "        #print(last_output[-1])\n",
        "        optimizer.zero_grad()\n",
        "        err = loss(last_output, target)\n",
        "        err.backward()#retain_graph=True\n",
        "        optimizer.step()\n",
        "        if i % 8 == 0:\n",
        "          print(\"target \", target)\n",
        "          print(\"Loss is \",err , i, epoch)\n",
        "          print(\"Last output \",last_output[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3000 0\n",
            "\n",
            "Epoch  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 0 0\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 8 0\n",
            "Last output  tensor([0.0099, 0.0100, 0.0101, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 16 0\n",
            "Last output  tensor([0.0100, 0.0100, 0.0101, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 24 0\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 32 0\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 40 0\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 48 0\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  1\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 0 1\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 8 1\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 16 1\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 24 1\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 32 1\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 40 1\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 48 1\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0099], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  2\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 0 2\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0099], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 8 2\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0099], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 16 2\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0099], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 24 2\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0099], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3862, device='cuda:0', grad_fn=<NllLossBackward>) 32 2\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0099], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3862, device='cuda:0', grad_fn=<NllLossBackward>) 40 2\n",
            "Last output  tensor([0.0101, 0.0099, 0.0101, 0.0099], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 48 2\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  3\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 0 3\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0101], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 8 3\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 16 3\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 24 3\n",
            "Last output  tensor([0.0100, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 32 3\n",
            "Last output  tensor([0.0100, 0.0099, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 40 3\n",
            "Last output  tensor([0.0100, 0.0099, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 48 3\n",
            "Last output  tensor([0.0100, 0.0099, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  4\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 0 4\n",
            "Last output  tensor([0.0100, 0.0099, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 8 4\n",
            "Last output  tensor([0.0100, 0.0098, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3861, device='cuda:0', grad_fn=<NllLossBackward>) 16 4\n",
            "Last output  tensor([0.0100, 0.0091, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3857, device='cuda:0', grad_fn=<NllLossBackward>) 24 4\n",
            "Last output  tensor([0.0100, 0.0076, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3848, device='cuda:0', grad_fn=<NllLossBackward>) 32 4\n",
            "Last output  tensor([0.0104, 0.0066, 0.0100, 0.0085], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3858, device='cuda:0', grad_fn=<NllLossBackward>) 40 4\n",
            "Last output  tensor([0.0103, 0.0089, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3844, device='cuda:0', grad_fn=<NllLossBackward>) 48 4\n",
            "Last output  tensor([0.0117, 0.0078, 0.0101, 0.0098], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  5\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3840, device='cuda:0', grad_fn=<NllLossBackward>) 0 5\n",
            "Last output  tensor([0.0122, 0.0075, 0.0102, 0.0098], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3813, device='cuda:0', grad_fn=<NllLossBackward>) 8 5\n",
            "Last output  tensor([0.0155, 0.0068, 0.0102, 0.0098], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3789, device='cuda:0', grad_fn=<NllLossBackward>) 16 5\n",
            "Last output  tensor([0.0194, 0.0069, 0.0125, 0.0091], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 24 5\n",
            "Last output  tensor([0.0098, 0.0096, 0.0099, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 32 5\n",
            "Last output  tensor([0.0098, 0.0096, 0.0099, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3862, device='cuda:0', grad_fn=<NllLossBackward>) 40 5\n",
            "Last output  tensor([0.0098, 0.0090, 0.0099, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3825, device='cuda:0', grad_fn=<NllLossBackward>) 48 5\n",
            "Last output  tensor([0.0142, 0.0077, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  6\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3840, device='cuda:0', grad_fn=<NllLossBackward>) 0 6\n",
            "Last output  tensor([0.0125, 0.0083, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3858, device='cuda:0', grad_fn=<NllLossBackward>) 8 6\n",
            "Last output  tensor([0.0105, 0.0094, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3859, device='cuda:0', grad_fn=<NllLossBackward>) 16 6\n",
            "Last output  tensor([0.0104, 0.0095, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3859, device='cuda:0', grad_fn=<NllLossBackward>) 24 6\n",
            "Last output  tensor([0.0104, 0.0095, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3858, device='cuda:0', grad_fn=<NllLossBackward>) 32 6\n",
            "Last output  tensor([0.0105, 0.0094, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3855, device='cuda:0', grad_fn=<NllLossBackward>) 40 6\n",
            "Last output  tensor([0.0107, 0.0091, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3848, device='cuda:0', grad_fn=<NllLossBackward>) 48 6\n",
            "Last output  tensor([0.0115, 0.0084, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  7\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3845, device='cuda:0', grad_fn=<NllLossBackward>) 0 7\n",
            "Last output  tensor([0.0117, 0.0082, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 8 7\n",
            "Last output  tensor([0.0098, 0.0096, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 16 7\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 24 7\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 32 7\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 40 7\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 48 7\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  8\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 0 8\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 8 8\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 16 8\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 24 8\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 32 8\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 40 8\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 48 8\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  9\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 0 9\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 8 9\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 16 9\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 24 9\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 32 9\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 40 9\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 48 9\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  10\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 0 10\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 8 10\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 16 10\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 24 10\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 32 10\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 40 10\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 48 10\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  11\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 0 11\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 8 11\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 16 11\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 24 11\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 32 11\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 40 11\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 48 11\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  12\n",
            "target  tensor([1], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 0 12\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([1], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 8 12\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([1], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 16 12\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([1], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 24 12\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([1], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 32 12\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([1], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 40 12\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([1], device='cuda:0')\n",
            "Loss is  tensor(1.3863, device='cuda:0', grad_fn=<NllLossBackward>) 48 12\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  13\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 0 13\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 8 13\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 16 13\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 24 13\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 32 13\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 40 13\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3864, device='cuda:0', grad_fn=<NllLossBackward>) 48 13\n",
            "Last output  tensor([0.0098, 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Epoch  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WCzqL7MHU05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}