{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmyth742/EEG-BCI/blob/master/DeepLearningCNN-LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "walmaCfwHT07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "d44f01d8-957d-4db0-fc1f-bed1f5f0aa89"
      },
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.12.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU-bZAV-HUrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "##### START OF ADDITION OF MY CODE\n",
        "\n",
        "import numpy as np\n",
        "import os.path\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import sys\n",
        "\n",
        "## PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import Tensor\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "import math #for calculus\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlJq32ymHUtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## END OF IMPORTS\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#file_id = '1FrXb6rTyqpE5SmNtP8HhygDmFf9Lw896'\n",
        "file_id = '1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG' ##1.mat\n",
        "#https://drive.google.com/open?id=1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx\n",
        "file_id = '1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx'\n",
        "#https://drive.google.com/open?id=1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('./train3.mat')\n",
        "#mat = loadmat('train3.mat')\n",
        "mat = sio.loadmat('train3.mat', squeeze_me=True, struct_as_record=False)\n",
        "data=[]\n",
        "\n",
        "## in class      \n",
        "device='cuda:0'\n",
        "learning_rate=0.01\n",
        "weight_decay=0.000001 \n",
        "momentum=0.9\n",
        "batch_size=200\n",
        "\n",
        "o=mat['o']\n",
        "\n",
        "data=mat['o'].data\n",
        "#print(data[200][21])\n",
        "labels=mat['o'].marker\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhXrIcR8HUvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "272de108-bbb1-4361-d1c6-e77b6afa8039"
      },
      "source": [
        "## video maker and data extractor\n",
        "\n",
        "pos=np.zeros((22,3), dtype=int)\n",
        "\n",
        "pos[0]=-2,10,0\n",
        "pos[1]=2,10,0\n",
        "pos[3]=-4,7,3\n",
        "pos[4]=4,7,3\n",
        "pos[5]=-5,0,4\n",
        "pos[6]=5,0,4\n",
        "pos[7]=-4,-7,3\n",
        "pos[8]=4,-7,3\n",
        "pos[9]=-2,-10,0\n",
        "pos[10]=2,-10,0\n",
        "pos[11]=-7,0,-5\n",
        "pos[12]=7,0,5\n",
        "pos[13]=-6,6,0\n",
        "pos[14]=6,6,0\n",
        "pos[15]=-7,0,0\n",
        "pos[16]=7,0,0\n",
        "pos[17]=-6,-6,0\n",
        "pos[18]=6,-6,0\n",
        "pos[19]=0,7,4\n",
        "pos[20]=0,0,6\n",
        "pos[21]=0,-7,4\n",
        "\n",
        "def make_3d_point(x,y,z,r,theta,phi):\n",
        "  return [\n",
        "      x + int(r * math.cos(theta)*math.sin(phi)),\n",
        "      y + int(r * math.sin(theta)*math.sin(phi)),\n",
        "      z + int(r * math.cos(phi))\n",
        "         ]\n",
        "\n",
        "def make_3d_image(image3d_data):\n",
        "  \n",
        "  #creating the matrix\n",
        "  matrix = np.zeros([4,16,21])\n",
        "  \n",
        "  #looping through data\n",
        "  for point in image3d_data:\n",
        "    \n",
        "    # creating the indice by shifting the coordinate system from the center to left corner\n",
        "    newpoint = [int(point[0]) + 8,int(point[1]) + 10,int(point[2]) + 1]\n",
        "    \n",
        "    if newpoint[0] >= matrix.shape[2] or newpoint[1] >= matrix.shape[1] or newpoint[2] >= matrix.shape[0] or newpoint[0] < 0 or newpoint[1] < 0 or newpoint[2] < 0:\n",
        "      continue\n",
        "      \n",
        "    #the maximum value\n",
        "    cap = 300 + 300 #300 based on the data, 300 because of the shift\n",
        "    \n",
        "    #for scaling the values between 0 and 255\n",
        "    scale = 255/cap\n",
        "    \n",
        "    #assigning the value\n",
        "    if int(point[3]) >= 0 and int(point[3]) <= cap:\n",
        "      matrix[newpoint[2],newpoint[1],newpoint[0]] = int(point[3]*scale)\n",
        "    elif int(point[3]) > cap:\n",
        "      matrix[newpoint[2],newpoint[1],newpoint[0]] = int(cap*scale)\n",
        "    else:\n",
        "      matrix[newpoint[2],newpoint[1],newpoint[0]] = 0\n",
        "    \n",
        "    #creating variables for creating a virtual sphere around poi\n",
        "    rho = [2,3] # distance (in pixels) that we are interpolating from poi\n",
        "    #theta  angle in radians    [0,2pi]\n",
        "    #phi    angle in radians    [0, pi]\n",
        "    \n",
        "    #creating new interpolated points\n",
        "    for r in rho:\n",
        "      for theta in range(0,360,45):\n",
        "        for phi in range(0,180,45):\n",
        "          p = make_3d_point(newpoint[0],newpoint[1],newpoint[2],r,math.radians(theta),math.radians(phi))\n",
        "          \n",
        "          #checking if its in bounds\n",
        "          if p[0] < matrix.shape[2] and p[1] < matrix.shape[1] and p[2] < matrix.shape[0] and p[0] >= 0 and p[1] >= 0 and p[2] >= 0:\n",
        "\n",
        "            \n",
        "            #assigning the value to the matrix, scaled down by distance\n",
        "            if int(point[3]) >= 0 and int(point[3]) <= cap:\n",
        "              if matrix[p[2],p[1],p[0]] == 0:\n",
        "                matrix[p[2],p[1],p[0]] = int(point[3]/r*scale)\n",
        "            elif int(point[3]) > cap:\n",
        "              if matrix[p[2],p[1],p[0]] == 0:\n",
        "                matrix[p[2],p[1],p[0]] = int(cap/r*scale)\n",
        "            else:\n",
        "              if matrix[p[2],p[1],p[0]] == 0:\n",
        "                matrix[p[2],p[1],p[0]] = 0\n",
        "            \n",
        "  return matrix\n",
        "\n",
        "\n",
        "start = 228154\n",
        "end   = 229154\n",
        "\n",
        "newdata = np.add(data,300).reshape([22,data.shape[0]])\n",
        "\n",
        "video_stream = np.zeros([end-start,1,4,16,21])\n",
        "video_stream[0,0] = make_3d_image(np.hstack((pos,newdata[:,start].reshape([22,1]))))\n",
        "\n",
        "print(video_stream.shape)\n",
        "\n",
        "for t in range(start+1,end,1):\n",
        " \n",
        "  #create x,y,z,value for timestep t\n",
        "  data3d = np.hstack((pos,newdata[:,t].reshape([22,1])))\n",
        "  \n",
        "  #make image - with interpolated data for timestep t\n",
        "  result = make_3d_image(data3d)\n",
        "  \n",
        "  #add image to video stream\n",
        "  video_stream[t-start,0] = result\n",
        "  \n",
        "  \n",
        "maxValue = np.amax(video_stream)\n",
        "minValue = np.amin(video_stream)\n",
        "\n",
        "print(maxValue)\n",
        "print(minValue)\n",
        "#print(video_stream[0,0,3])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 1, 4, 16, 21)\n",
            "215.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXFEMyYAHUyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "2beeb04c-dace-43e8-8132-28819dbbfbfd"
      },
      "source": [
        "class EEGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EEGNet, self).__init__()\n",
        "        self.T = 120\n",
        "        \n",
        "        # Layer 1\n",
        "        self.conv1 = nn.Conv3d(1,6,1, stride=1,padding=(1,1,1))\n",
        "        self.conv2 = nn.Conv3d(6,6,1, stride=1)\n",
        "        self.conv3 = nn.Conv3d(6,1,1, stride=1)\n",
        "        self.pooling1 = nn.MaxPool3d(2, stride=1)\n",
        "        \n",
        "        #Layer 2\n",
        "        self.conv4 = nn.Conv3d(1,6,2, stride=1)\n",
        "        self.conv5 = nn.Conv3d(6,6,2, stride=1)\n",
        "        self.conv6 = nn.Conv3d(6,1,2, stride=1)\n",
        "        self.pooling2 = nn.MaxPool3d(1, stride=1)\n",
        "        \n",
        "        # Layer 3\n",
        "        self.conv7 = nn.Conv3d(1,3,2, stride=1)\n",
        "        self.pooling3 = nn.MaxPool3d(1, stride=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        x = F.elu(self.conv1(x))\n",
        "        x = F.elu(self.conv2(x))\n",
        "        x = F.elu(self.conv3(x))\n",
        "        # Layer 2\n",
        "        x = self.pooling1(x)\n",
        "        \n",
        "        x = F.elu(self.conv4(x))\n",
        "        x = F.elu(self.conv5(x))\n",
        "        x = F.elu(self.conv6(x))\n",
        "        # Layer 2\n",
        "        x = self.pooling2(x)\n",
        "        \n",
        "        x = F.elu(self.conv7(x))\n",
        "        x = self.pooling3(x)\n",
        "        \n",
        "        print(\"after forward layer 2\",x.shape)\n",
        "\n",
        "        return x    \n",
        "\n",
        "class Combine(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Combine, self).__init__()\n",
        "        self.cnn = EEGNet().float()\n",
        "        self.rnn = nn.LSTM(320, 10, 2, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, timesteps, C, H, W = x.size()\n",
        "        c_in = x.view(batch_size * timesteps, C, H, W)\n",
        "        c_out = self.cnn(c_in)\n",
        "        r_in = c_out.view(batch_size, timesteps, -1)\n",
        "        r_out = self.rnn(r_in)\n",
        "        return F.log_softmax(r_out, dim=1)\n",
        "      \n",
        " \n",
        "      \n",
        "def evaluate(model, X, Y, params = [\"acc\"]):\n",
        "    results = []\n",
        "    batch_size = 10000\n",
        "    \n",
        "    predicted = []\n",
        "    for i in range(len(X)//batch_size):\n",
        "        s = i*batch_size\n",
        "        e = i*batch_size+batch_size\n",
        "        \n",
        "        inputs = Variable(torch.from_numpy(X[s:e]))\n",
        "        pred = model(inputs.float())\n",
        "        \n",
        "        predicted.append(pred.data.cpu().numpy())\n",
        "        \n",
        "    inputs = Variable(torch.from_numpy(X))\n",
        "\n",
        "    predicted = model(inputs.float())\n",
        "\n",
        "    predicted = predicted.data.cpu().numpy()\n",
        "\n",
        "    \n",
        "    for param in params:\n",
        "        if param == 'acc':\n",
        "            print(\"acc causing issue\")\n",
        "            print(\"y shape is \", Y.shape)\n",
        "            print(\"predicted shape is \",np.round(predicted).shape)\n",
        "            #results.append(accuracy_score(Y, np.round(predicted)))\n",
        "        if param == \"auc\":\n",
        "            print(\"auc causing issue\")\n",
        "            #results.append(roc_auc_score(Y, np.round(predicted)))\n",
        "        #if param == \"recall\":\n",
        "            #print(\"recall causing issue\")\n",
        "            #results.append(recall_score(Y, np.round(predicted)))\n",
        "        #if param == \"precision\":\n",
        "            #print(\"precision causing issue\")\n",
        "            #results.append(precision_score(Y, np.round(predicted)))\n",
        "        #if param == \"fmeasure\":\n",
        "            #print(\"fmeasure causing issue\")\n",
        "            #precision = precision_score(Y, np.round(predicted))\n",
        "            #recall = recall_score(Y, np.round(predicted))\n",
        "            #results.append(2*precision*recall/ (precision+recall))\n",
        "    return results\n",
        "\n",
        "      \n",
        "#print(maxValue)\n",
        "#print(minValue)\n",
        "\n",
        "   \n",
        "#print(video_stream.shape)\n",
        "#print(img)\n",
        "\n",
        "## END OF ADDITION OF MY CODE\n",
        "      \n",
        "            \n",
        "net = EEGNet().float()\n",
        "#net.forward(Variable(torch.randn(1, 1, 4, 16, 21)))\n",
        "#print(torch.randn(1, 1, 4, 16, 21))\n",
        "net.forward(Variable(torch.FloatTensor(video_stream)))\n",
        "\n",
        "criterion =  nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "video_stream.astype(float)\n",
        "\n",
        "#X_train = torch.randn(1, 1, 4, 16, 21)\n",
        "X_train = video_stream.astype('float32') # our generated image\n",
        "#y_train = torch.randn(1, 1, 4, 16, 21)\n",
        "#y_train = torch.randn(1, 3, 2, 14, 19)\n",
        "\"\"\"\n",
        "y_train = video_stream.astype('float32') # our generated image\n",
        "\n",
        "X_val = torch.randn(1, 1, 4, 16, 21)\n",
        "#y_val = torch.randn(1, 1, 4, 16, 21)\n",
        "y_val = torch.randn(1, 3, 2, 14, 19)\n",
        "\n",
        "X_test = torch.randn(1, 1, 4, 16, 21)\n",
        "#y_test = torch.randn(1, 1, 4, 16, 21)\n",
        "y_test = torch.randn(11, 3, 2, 14, 19)\"\"\"\n",
        "y_train = video_stream.astype('float32')\n",
        "#y_train = labels.astype('float32')\n",
        "\n",
        "X_val = video_stream.astype('float32')\n",
        "#X_val = np.random.rand(200, 16, 21, 4).astype('float32')\n",
        "#y_val = np.round(np.random.rand(100).astype('float32'))#og\n",
        "y_val = video_stream.astype('float32')\n",
        "\n",
        "X_test = video_stream.astype('float32')\n",
        "#X_test = np.random.rand(200, 16, 21, 4).astype('float32')\n",
        "#y_test = np.round(np.random.rand(100).astype('float32'))\n",
        "y_test =  video_stream.astype('float32')\n",
        "\n",
        "batch_size = 20000\n",
        "\n",
        "for epoch in range(100000):  # loop over the dataset multiple times\n",
        "    print(\"\\nEpoch \", epoch)\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    for i in range(len(X_train)//batch_size-1):\n",
        "        s = i*batch_size\n",
        "        e = i*batch_size+batch_size\n",
        "        \n",
        "        inputs = torch.from_numpy(X_train[s:e])\n",
        "        labels = torch.FloatTensor(np.array([y_train[s:e]]))#.T*1.0\n",
        "        # wrap them in Variable\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs.float())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.data\n",
        "        print(running_loss)\n",
        "    \n",
        "    # Validation accuracy\n",
        "    params = [\"acc\", \"auc\", \"fmeasure\"]\n",
        "    print(params)\n",
        "    print(\"Training Loss \", running_loss)\n",
        "    print(\"Train - \", evaluate(net, X_train, y_train, params))\n",
        "    print(\"Validation - \", evaluate(net, X_val, y_val, params))\n",
        "    print(\"Test - \", evaluate(net, X_test, y_test, params))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after forward layer 2 torch.Size([1000, 3, 1, 13, 18])\n",
            "\n",
            "Epoch  0\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0\n",
            "after forward layer 2 torch.Size([1000, 3, 1, 13, 18])\n",
            "acc causing issue\n",
            "y shape is  (1000, 1, 4, 16, 21)\n",
            "predicted shape is  (1000, 3, 1, 13, 18)\n",
            "auc causing issue\n",
            "Train -  []\n",
            "after forward layer 2 torch.Size([1000, 3, 1, 13, 18])\n",
            "acc causing issue\n",
            "y shape is  (1000, 1, 4, 16, 21)\n",
            "predicted shape is  (1000, 3, 1, 13, 18)\n",
            "auc causing issue\n",
            "Validation -  []\n",
            "after forward layer 2 torch.Size([1000, 3, 1, 13, 18])\n",
            "acc causing issue\n",
            "y shape is  (1000, 1, 4, 16, 21)\n",
            "predicted shape is  (1000, 3, 1, 13, 18)\n",
            "auc causing issue\n",
            "Test -  []\n",
            "\n",
            "Epoch  1\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-f3bf56b28022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train - \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation - \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test - \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-f3bf56b28022>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, X, Y, params)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-f3bf56b28022>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Layer 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    474\u001b[0m                             self.dilation, self.groups)\n\u001b[1;32m    475\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 476\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WCzqL7MHU05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}